# üìö Notable-LLM-Research-Papers üéì‚ú®
Hello, curious reader! üëã Are you someone who loves exploring the cutting-edge world of AI and large language models (LLMs)? Or maybe you're a researcher, developer, or simply an enthusiast wondering about how these incredible technologies are evolving? Either way, you're in the right place. This repository is your gateway to **500+ groundbreaking research papers** that capture the exciting developments in AI across 2024 and beyond.

## üöÄ What‚Äôs in This Repository?
These papers cover a *wide spectrum of topics*, ranging from improving model efficiency to aligning AI with human values, and even diving into the magic of multimodal models. The field of AI is advancing faster than ever, and these works showcase the brilliant ideas and innovations shaping the future.

### The papers broadly fall under the following categories:

---

### 1. **Model Architecture and Efficiency** üèóÔ∏è‚ö°
   Papers that introduce innovative architectures, explore scaling laws, or improve the efficiency of LLMs. These works aim to make AI faster, cheaper, and better.

---

### 2. **Preference Optimization and RLHF (Reinforcement Learning with Human Feedback)** ü§ùüí°
   Research exploring how to align AI with human preferences, ensuring outputs are not just accurate but also ethical, safe, and aligned with societal values.

---

### 3. **Multimodal Models** üñºÔ∏èüéôÔ∏è‚úçÔ∏è
   Ever wondered how AI can *see*, *read*, and *understand* all at once? These papers focus on models that combine multiple types of data, like images, text, and audio, to build richer, more versatile systems.

---

### 4. **Long-Context Learning and Inference** üß†üåÄ
   Tackling the challenges of long-context understanding, these papers discuss how to extend the memory of LLMs, making them capable of reasoning across longer documents or conversations.

---

### 5. **Reasoning and Knowledge** üîçüß†
   From enabling AI to solve complex puzzles to improving its reasoning capabilities, these papers explore how LLMs "think" and manage the vast knowledge they've been trained on.

---

### 6. **Quantization and Compression** üìèüóúÔ∏è
   Smaller, faster, and more efficient‚Äîthese papers delve into techniques like quantization and compression to make AI models more practical for real-world applications.

---

### 7. **Evaluation and Benchmarks** üìäüìà
   A great model needs great evaluation. These papers propose new benchmarks and methodologies to assess the capabilities of AI systems more rigorously.

---

### 8. **Instruction Tuning and Alignment** üìùüéØ
   Want your AI to follow your instructions perfectly? These papers refine how we align LLMs to understand and execute instructions across various tasks.

---

### 9. **Surveys and Meta-Analysis** üî¨üìö
   Meta-level research analyzing trends, methods, and applications in AI. Perfect for getting a bird‚Äôs-eye view of where the field is heading.

---

### 10. **Applications and Tooling** üîßüåç
   Papers showcasing how LLMs are applied in diverse domains, from healthcare to coding and everything in between. These highlight the transformative power of AI in the real world.

---

## üåü Why Should You Care?
These papers represent the state of the art in AI research. Whether you're here to **stay updated**, **seek inspiration**, or **find practical tools**, this collection is a treasure trove for AI enthusiasts. Dive in, explore, and let your curiosity guide you! üåê‚ú®

---

Ready to start? üéâ Browse the list and explore the exciting breakthroughs shaping the future of AI! üöÄ

---

| üî¢ **S.No.** | üìù **Paper Title**                                                                                                      | üîó **Link**                         |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 1            | LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning                                                      | [Link](https://arxiv.org/abs/2401.01325) |
| 2            | Knowledge Fusion of Large Language Models                                                                            | [Link](https://arxiv.org/abs/2401.10491) |
| 3            | A Comprehensive Study of Knowledge Editing for Large Language Models                                                 | [Link](https://arxiv.org/abs/2401.01286) |
| 4            | DiffusionGPT: LLM-Driven Text-to-Image Generation System                                                             | [Link](https://arxiv.org/abs/2401.10061) |
| 5            | Tuning Language Models by Proxy                                                                                      | [Link](https://arxiv.org/abs/2401.08565) |
| 6            | An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models                  | [Link](https://arxiv.org/abs/2401.06692) |
| 7            | Soaring from 4K to 400K: Extending LLM‚Äôs Context with Activation Beacon                                              | [Link](https://arxiv.org/abs/2401.03462) |
| 8            | VMamba: Visual State Space Model                                                                                     | [Link](https://arxiv.org/abs/2401.10166) |
| 9            | LLaMA Beyond English: An Empirical Study on Language Capability Transfer                                             | [Link](https://arxiv.org/abs/2401.01055) |
| 10           | DeepSeek LLM: Scaling Open-Source Language Models with Longtermism                                                   | [Link](https://arxiv.org/abs/2401.02954) |
| 11           | Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM                                     | [Link](https://arxiv.org/abs/2401.02994) |
| 12           | LLaMA Pro: Progressive LLaMA with Block Expansion                                                                    | [Link](https://arxiv.org/abs/2401.02415) |
| 13           | RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation                                                 | [Link](https://arxiv.org/abs/2401.04679) |
| 14           | Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text                                         | [Link](https://arxiv.org/abs/2401.12070) |
| 15           | Rephrasing the Web: A Recipe for Compute and Data-Efficient Language Modeling                                        | [Link](https://arxiv.org/abs/2401.16380) |
| 16           | WARM: On the Benefits of Weight Averaged Reward Models                                                               | [Link](https://arxiv.org/abs/2401.12187) |
| 17           | SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection                                 | [Link](https://arxiv.org/abs/2401.13160) |
| 18           | A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity                               | [Link](https://arxiv.org/abs/2401.01967) |
| 19           | Mixtral of Experts                                                                                                  | [Link](https://arxiv.org/abs/2401.04088) |
| 20           | MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts                                           | [Link](https://arxiv.org/abs/2401.04081) |
| 21           | Code Generation with AlphaCodium: From Prompt Engineering to Flow Engineering                                       | [Link](https://arxiv.org/abs/2401.08500) |
| 22           | EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty                                                 | [Link](https://arxiv.org/abs/2401.15077) |
| 23           | KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization                                 | [Link](https://arxiv.org/abs/2401.18079) |
| 24           | A Closer Look at AUROC and AUPRC under Class Imbalance                                                              | [Link](https://arxiv.org/abs/2401.06091) |
| 25           | Transformers are Multi-State RNNs                                                                                   | [Link](https://arxiv.org/abs/2401.06104) |
| 26           | LLM Augmented LLMs: Expanding Capabilities through Composition                                                     | [Link](https://arxiv.org/abs/2401.02412) |
| 27           | Rethinking Patch Dependence for Masked Autoencoders                                                                 | [Link](https://arxiv.org/abs/2401.14391) |
| 28           | Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models                                         | [Link](https://arxiv.org/abs/2401.00788) |
| 29           | Pix2gestalt: Amodal Segmentation by Synthesizing Wholes                                                             | [Link](https://arxiv.org/abs/2401.14398) |
| 30           | RAG vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture                                           | [Link](https://arxiv.org/abs/2401.08406) |
| 31           | An Experimental Design Framework for Label-Efficient Supervised Finetuning of Large Language Models                | [Link](https://arxiv.org/abs/2401.06692) |
| 32           | Knowledge Fusion of Large Language Models                                                                          | [Link](https://arxiv.org/abs/2401.10491) |
| 33           | Scalable Pre-training of Large Autoregressive Image Models                                                          | [Link](https://arxiv.org/abs/2401.08541) |
| 34           | SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning Capabilities                                     | [Link](https://arxiv.org/abs/2401.12168) |
| 35           | Multimodal Pathway: Improve Transformers with Irrelevant Data from Other Modalities                                 | [Link](https://arxiv.org/abs/2401.14405) |
| 36           | MambaByte: Token-free Selective State Space Model                                                                   | [Link](https://arxiv.org/abs/2401.13660) |
| 37           | ReFT: Reasoning with Reinforced Fine-Tuning                                                                        | [Link](https://arxiv.org/abs/2401.08967) |
| 38           | Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models                                       | [Link](https://arxiv.org/abs/2401.01335) |
| 39           | Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training                                        | [Link](https://arxiv.org/abs/2401.05566) |
| 40           | Denoising Vision Transformers                                                                                      | [Link](https://arxiv.org/abs/2401.02957) |
| 41           | Self-Rewarding Language Models                                                                                      | [Link](https://arxiv.org/abs/2401.10020) |
| 42           | LoRA+: Efficient Low Rank Adaptation of Large Models                                                                  | [Link](https://arxiv.org/abs/2402.12354) |
| 43           | MobileVLM V2: Faster and Stronger Baseline for Vision Language Model                                                  | [Link](https://arxiv.org/abs/2402.03766) |
| 44           | Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight in the Real World for Meeting Summarization? | [Link](https://arxiv.org/abs/2402.00841) |
| 45           | ODIN: Disentangled Reward Mitigates Hacking in RLHF                                                                   | [Link](https://arxiv.org/abs/2402.07319) |
| 46           | Genie: Generative Interactive Environments                                                                            | [Link](https://arxiv.org/abs/2402.15391) |
| 47           | A Phase Transition Between Positional and Semantic Learning in a Solvable Model of Dot-Product Attention             | [Link](https://arxiv.org/abs/2402.03902) |
| 48           | Neural Network Diffusion                                                                                            | [Link](https://arxiv.org/abs/2402.13144) |
| 49           | More Agents Is All You Need                                                                                          | [Link](https://arxiv.org/abs/2402.05120) |
| 50           | Scaling Laws for Downstream Task Performance of Large Language Models                                                | [Link](https://arxiv.org/abs/2402.04177) |
|--------------|---------------------------------------------------------------------------------------------------------------------|------------------------------------|
| 51           | Repeat After Me: Transformers are Better than State Space Models at Copying                                         | [Link](https://arxiv.org/abs/2402.01032) |
| 52           | Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models                          | [Link](https://arxiv.org/abs/2402.19427) |
| 53           | AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling                                                      | [Link](https://arxiv.org/abs/2402.12226) |
| 54           | BASE TTS: Lessons From Building a Billion-Parameter Text-to-Speech Model on 100K Hours of Data                       | [Link](https://arxiv.org/abs/2402.08093) |
| 55           | LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration                                | [Link](https://arxiv.org/abs/2402.11550) |
| 56           | LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens                                                      | [Link](https://arxiv.org/abs/2402.13753) |
| 57           | Policy Improvement using Language Feedback Models                                                                   | [Link](https://arxiv.org/abs/2402.07876) |
| 58           | DoRA: Weight-Decomposed Low-Rank Adaptation                                                                          | [Link](https://arxiv.org/abs/2402.09353) |
| 59           | FindingEmo: An Image Dataset for Emotion Recognition in the Wild                                                    | [Link](https://arxiv.org/abs/2402.01355) |
| 60           | TinyLLaVA: A Framework of Small-scale Large Multimodal Models                                                       | [Link](https://arxiv.org/abs/2402.14289) |
| 61           | Vision Superalignment: Weak-to-Strong Generalization for Vision Foundation Models                                   | [Link](https://arxiv.org/abs/2402.03749) |
| 62           | When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method                                   | [Link](https://arxiv.org/abs/2402.17193) |
| 63           | Step-On-Feet Tuning: Scaling Self-Alignment of LLMs via Bootstrapping                                               | [Link](https://arxiv.org/abs/2402.07610) |
| 64           | Suppressing Pink Elephants with Direct Principle Feedback                                                           | [Link](https://arxiv.org/abs/2402.07896) |
| 65           | The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits                                                   | [Link](https://arxiv.org/abs/2402.17764) |
| 66           | LiPO: Listwise Preference Optimization through Learning-to-Rank                                                    | [Link](https://arxiv.org/abs/2402.01878) |
| 67           | Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model                                         | [Link](https://arxiv.org/abs/2402.07610) |
| 68           | The Boundary of Neural Network Trainability is Fractal                                                             | [Link](https://arxiv.org/abs/2402.06184) |
| 69           | Recovering the Pre-Fine-Tuning Weights of Generative Models                                                        | [Link](https://arxiv.org/abs/2402.10208) |
| 70           | Scaling Laws for Fine-Grained Mixture of Experts                                                                   | [Link](https://arxiv.org/abs/2402.07871) |
| 71           | Direct Language Model Alignment from Online AI Feedback                                                            | [Link](https://arxiv.org/abs/2402.04792) |
| 72           | CARTE: Pretraining and Transfer for Tabular Learning                                                               | [Link](https://arxiv.org/abs/2402.16785) |
| 73           | Grandmaster-Level Chess Without Search                                                                             | [Link](https://arxiv.org/abs/2402.04494) |
| 74           | Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs                   | [Link](https://arxiv.org/abs/2402.14740) |
| 75           | Reformatted Alignment                                                                                              | [Link](https://arxiv.org/abs/2402.12219) |
| 76           | OLMo: Accelerating the Science of Language Models                                                                  | [Link](https://arxiv.org/abs/2402.00838) |
| 77           | FinTral: A Family of GPT-4 Level Multimodal Financial Large Language Models                                        | [Link](https://arxiv.org/abs/2402.10986) |
| 78           | Mixtures of Experts Unlock Parameter Scaling for Deep RL                                                          | [Link](https://arxiv.org/abs/2402.08609) |
| 79           | Generative Representational Instruction Tuning                                                                     | [Link](https://arxiv.org/abs/2402.09906) |
| 80           | World Model on Million-Length Video And Language With RingAttention                                               | [Link](https://arxiv.org/abs/2402.08268) |
| 81           | Efficient Exploration for LLMs                                                                                    | [Link](https://arxiv.org/abs/2402.00396) |
| 82           | YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information                                    | [Link](https://arxiv.org/abs/2402.13616) |
| 83           | Towards Cross-Tokenizer Distillation: The Universal Logit Distillation Loss for LLMs                                  | [Link](https://arxiv.org/abs/2402.12030) |
| 84           | Mixtures of Experts Unlock Parameter Scaling for Deep RL                                                             | [Link](https://arxiv.org/abs/2402.08609) |
| 85           | Sora Generates Videos with Stunning Geometrical Consistency                                                         | [Link](https://arxiv.org/abs/2402.17403) |
| 86           | BASE TTS: Lessons From Building a Billion-Parameter Text-to-Speech Model on 100K Hours of Data                       | [Link](https://arxiv.org/abs/2402.08093) |
| 87           | Back to Basics: Revisiting REINFORCE Style Optimization for Learning from Human Feedback in LLMs                    | [Link](https://arxiv.org/abs/2402.14740) |
| 88           | Griffin: Mixing Gated Linear Recurrences with Local Attention for Efficient Language Models                         | [Link](https://arxiv.org/abs/2402.19427) |
| 89           | DoRA: Weight-Decomposed Low-Rank Adaptation                                                                          | [Link](https://arxiv.org/abs/2402.09353) |
| 90           | The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits                                                   | [Link](https://arxiv.org/abs/2402.17764) |
| 91           | Efficient Exploration for LLMs                                                                                      | [Link](https://arxiv.org/abs/2402.00396) |
| 92           | Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training                              | [Link](https://arxiv.org/abs/2405.15319) |
| 93           | You Only Cache Once: Decoder-Decoder Architectures for Language Models                                                | [Link](https://arxiv.org/abs/2405.05254) |
| 94           | gzip Predicts Data-dependent Scaling Laws                                                                             | [Link](https://arxiv.org/abs/2405.16684) |
| 95           | Self-Play Preference Optimization for Language Model Alignment                                                       | [Link](https://arxiv.org/abs/2405.00675) |
| 96           | PHUDGE: Phi-3 as Scalable Judge                                                                                      | [Link](https://arxiv.org/abs/2405.08029) |
| 97           | What Matters When Building Vision-Language Models?                                                                   | [Link](https://arxiv.org/abs/2405.02246) |
| 98           | Towards Modular LLMs by Building and Reusing a Library of LoRAs                                                      | [Link](https://arxiv.org/abs/2405.11157) |
| 99           | Contextual Position Encoding: Learning to Count What‚Äôs Important                                                     | [Link](https://arxiv.org/abs/2405.18719) |
| 100          | RLHF Workflow: From Reward Modeling to Online RLHF                                                                   | [Link](https://arxiv.org/abs/2405.07863) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 101          | Attention as an RNN                                                                                                  | [Link](https://arxiv.org/abs/2405.13956) |
| 102          | AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability                                        | [Link](https://arxiv.org/abs/2405.14129) |
| 103          | Instruction Tuning With Loss Over Instructions                                                                       | [Link](https://arxiv.org/abs/2405.14394) |
| 104          | LoRA Learns Less and Forgets Less                                                                                    | [Link](https://arxiv.org/abs/2405.09673) |
| 105          | Trans-LoRA: Towards Data-free Transferable Parameter Efficient Finetuning                                            | [Link](https://arxiv.org/abs/2405.17258) |
| 106          | VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections                                                 | [Link](https://arxiv.org/abs/2405.17991) |
| 107          | MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning                                                         | [Link](https://arxiv.org/abs/2405.12130) |
| 108          | LLaMA-NAS: Efficient Neural Architecture Search for Large Language Models                                            | [Link](https://arxiv.org/abs/2405.18377) |
| 109          | SimPO: Simple Preference Optimization with a Reference-Free Reward                                                   | [Link](https://arxiv.org/abs/2405.14734) |
| 110          | The Road Less Scheduled                                                                                             | [Link](https://arxiv.org/abs/2405.15682) |
| 111          | Fishing for Magikarp: Automatically Detecting Under-trained Tokens in Large Language Models                          | [Link](https://arxiv.org/abs/2405.05417) |
| 112          | Is Flash Attention Stable?                                                                                           | [Link](https://arxiv.org/abs/2405.02803) |
| 113          | Value Augmented Sampling for Language Model Alignment and Personalization                                            | [Link](https://arxiv.org/abs/2405.06639) |
| 114          | Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?                                                    | [Link](https://arxiv.org/abs/2405.05904) |
| 115          | vAttention: Dynamic Memory Management for Serving LLMs without PagedAttention                                       | [Link](https://arxiv.org/abs/2405.04437) |
| 116          | A Careful Examination of Large Language Model Performance on Grade School Arithmetic                                 | [Link](https://arxiv.org/abs/2405.00332) |
| 117          | Prometheus 2: An Open Source Language Model Specialized in Evaluating Other Language Models                         | [Link](https://arxiv.org/abs/2405.01535) |
| 118          | DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model                                  | [Link](https://arxiv.org/abs/2405.04434) |
| 119          | Dense Connector for MLLMs                                                                                           | [Link](https://arxiv.org/abs/2405.13800) |
| 120          | xLSTM: Extended Long Short-Term Memory                                                                               | [Link](https://arxiv.org/abs/2405.04517) |
| 121          | SLAB: Efficient Transformers with Simplified Linear Attention and Progressive Re-parameterized Batch Normalization  | [Link](https://arxiv.org/abs/2405.11582) |
| 122          | Xmodel-VLM: A Simple Baseline for Multimodal Vision Language Model                                                  | [Link](https://arxiv.org/abs/2405.09215) |
| 123          | Chameleon: Mixed-Modal Early-Fusion Foundation Models                                                               | [Link](https://arxiv.org/abs/2405.09818) |
| 124          | Is Bigger Edit Batch Size Always Better? An Empirical Study on Model Editing with Llama-3                           | [Link](https://arxiv.org/abs/2405.00664) |
| 125          | AlignGPT: Multi-modal Large Language Models with Adaptive Alignment Capability                                       | [Link](https://arxiv.org/abs/2405.14129) |
| 126          | The Prompt Report: A Systematic Survey of Prompting Techniques                                                       | [Link](https://arxiv.org/abs/2406.06608) |
| 127          | Creativity Has Left the Chat: The Price of Debiasing Language Models                                                 | [Link](https://arxiv.org/abs/2406.05587) |
| 128          | Show, Don‚Äôt Tell: Aligning Language Models with Demonstrated Feedback                                                | [Link](https://arxiv.org/abs/2406.00888) |
| 129          | WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild                                      | [Link](https://arxiv.org/abs/2406.04770) |
| 130          | Scalable MatMul-free Language Modeling                                                                               | [Link](https://arxiv.org/abs/2406.02528) |
| 131          | Never Miss A Beat: An Efficient Recipe for Context Window Extension of Large Language Models                         | [Link](https://arxiv.org/abs/2406.07138) |
| 132          | Boosting Large-scale Parallel Training Efficiency with C4: A Communication-Driven Approach                           | [Link](https://arxiv.org/abs/2406.04594) |
| 133          | Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models                             | [Link](https://arxiv.org/abs/2406.06563) |
| 134          | MLKV: Multi-Layer Key-Value Heads for Memory Efficient Transformer Decoding                                          | [Link](https://arxiv.org/abs/2406.09297) |
| 135          | Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling                            | [Link](https://arxiv.org/abs/2406.07522) |
| 136          | An Image is Worth 32 Tokens for Reconstruction and Generation                                                       | [Link](https://arxiv.org/abs/2406.07550) |
| 137          | Block Transformer: Global-to-Local Language Modeling for Fast Inference                                             | [Link](https://arxiv.org/abs/2406.02657) |
| 138          | 3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and Less Hallucination                          | [Link](https://arxiv.org/abs/2406.05132) |
| 139          | Transformers Need Glasses! Information Over-Squashing in Language Tasks                                             | [Link](https://arxiv.org/abs/2406.04267) |
| 140          | The Geometry of Categorical and Hierarchical Concepts in Large Language Models                                      | [Link](https://arxiv.org/abs/2406.01506) |
| 141          | BERTs are Generative In-Context Learners                                                                            | [Link](https://arxiv.org/abs/2406.04823) |
| 142          | An Empirical Study of Mamba-based Language Models                                                                   | [Link](https://arxiv.org/abs/2406.07887) |
| 143          | Discovering Preference Optimization Algorithms with and for Large Language Models                                   | [Link](https://arxiv.org/abs/2406.08414) |
| 144          | Magpie: Alignment Data Synthesis from Scratch by Prompting Aligned LLMs with Nothing                               | [Link](https://arxiv.org/abs/2406.08464) |
| 145          | Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation                                           | [Link](https://arxiv.org/abs/2406.06525) |
| 146          | Are We Done with MMLU?                                                                                             | [Link](https://arxiv.org/abs/2406.04127) |
| 147          | OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models                                                    | [Link](https://arxiv.org/abs/2406.01775) |
| 148          | Step-aware Preference Optimization: Aligning Preference with Denoising Performance at Each Step                    | [Link](https://arxiv.org/abs/2406.04314) |
| 149          | Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning                                              | [Link](https://arxiv.org/abs/2406.06469) |
| 150          | Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated Parameters                                      | [Link](https://arxiv.org/abs/2406.05955) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 151          | Simple and Effective Masked Diffusion Language Models                                                              | [Link](https://arxiv.org/abs/2406.07524) |
| 152          | The Prompt Report: A Systematic Survey of Prompting Techniques                                                     | [Link](https://arxiv.org/abs/2406.06608) |
| 153          | Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs                                    | [Link](https://arxiv.org/abs/2406.10216) |
| 154          | Be like a Goldfish, Don‚Äôt Memorize! Mitigating Memorization in Generative LLMs                                      | [Link](https://arxiv.org/abs/2406.10209) |
| 155          | TextGrad: Automatic ‚ÄúDifferentiation‚Äù via Text                                                                     | [Link](https://arxiv.org/abs/2406.07496) |
| 156          | Large Language Models Must Be Taught to Know What They Don‚Äôt Know                                                  | [Link](https://arxiv.org/abs/2406.08391) |
| 157          | What If We Recaption Billions of Web Images with LLaMA-3?                                                         | [Link](https://arxiv.org/abs/2406.08478) |
| 158          | Discovering Preference Optimization Algorithms with and for Large Language Models                                  | [Link](https://arxiv.org/abs/2406.08414) |
| 159          | An Image is Worth More Than 16x16 Patches: Exploring Transformers on Individual Pixels                             | [Link](https://arxiv.org/abs/2406.09415) |
| 160          | Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models                                        | [Link](https://arxiv.org/abs/2406.04271) |
| 161          | CRAG ‚Äì Comprehensive RAG Benchmark                                                                                | [Link](https://arxiv.org/abs/2406.04744) |
| 162          | Margin-aware Preference Optimization for Aligning Diffusion Models Without Reference                               | [Link](https://arxiv.org/abs/2406.06424) |
| 163          | Mixture-of-Agents Enhances Large Language Model Capabilities                                                      | [Link](https://arxiv.org/abs/2406.04692) |
| 164          | Large Language Model Unlearning via Embedding-Corrupted Prompts                                                   | [Link](https://arxiv.org/abs/2406.07933) |
| 165          | Bootstrapping Language Models with DPO Implicit Rewards                                                           | [Link](https://arxiv.org/abs/2406.09760) |
| 166          | THEANINE: Revisiting Memory Management in Long-term Conversations with Timeline-augmented Response Generation         | [Link](https://arxiv.org/abs/2406.10996) |
| 167          | Task Me Anything                                                                                                     | [Link](https://arxiv.org/abs/2406.11775) |
| 168          | Nemotron-4 340B Technical Report                                                                                     | [Link](https://arxiv.org/abs/2406.11704) |
| 169          | Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges                                       | [Link](https://arxiv.org/abs/2406.12624) |
| 170          | How Do Large Language Models Acquire Factual Knowledge During Pretraining?                                           | [Link](https://arxiv.org/abs/2406.11813) |
| 171          | mDPO: Conditional Preference Optimization for Multimodal Large Language Models                                       | [Link](https://arxiv.org/abs/2406.11839) |
| 172          | Unveiling Encoder-Free Vision-Language Models                                                                        | [Link](https://arxiv.org/abs/2406.11832) |
| 173          | HARE: HumAn pRiors, a key to small language model Efficiency                                                         | [Link](https://arxiv.org/abs/2406.11410) |
| 174          | Measuring Memorization in RLHF for Code Completion                                                                   | [Link](https://arxiv.org/abs/2406.11715) |
| 175          | DeepSeek-Coder-V2: Breaking the Barrier of Closed-Source Models in Code Intelligence                                 | [Link](https://arxiv.org/abs/2406.11931) |
| 176          | Iterative Length-Regularized Direct Preference Optimization: Improving 7B Language Models to GPT-4 Level             | [Link](https://arxiv.org/abs/2406.11817) |
| 177          | From RAGs to Rich Parameters: Probing How Language Models Utilize External Knowledge Over Parametric Information     | [Link](https://arxiv.org/abs/2406.12824) |
| 178          | DataComp-LM: In Search of the Next Generation of Training Sets for Language Models                                   | [Link](https://arxiv.org/abs/2406.11794) |
| 179          | Can Long-Context Language Models Subsume Retrieval, RAG, SQL, and More?                                              | [Link](https://arxiv.org/abs/2406.13121) |
| 180          | Instruction Pre-Training: Language Models are Supervised Multitask Learners                                         | [Link](https://arxiv.org/abs/2406.14491) |
| 181          | Can LLMs Learn by Teaching? A Preliminary Study                                                                     | [Link](https://arxiv.org/abs/2406.14629) |
| 182          | A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems                                                 | [Link](https://arxiv.org/abs/2406.14972) |
| 183          | LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs                                            | [Link](https://arxiv.org/abs/2406.15319) |
| 184          | MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression                                      | [Link](https://arxiv.org/abs/2406.14909) |
| 185          | Efficient Continual Pre-training by Mitigating the Stability Gap                                                    | [Link](https://arxiv.org/abs/2406.14833) |
| 186          | Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers                          | [Link](https://arxiv.org/abs/2406.16747) |
| 187          | WARP: On the Benefits of Weight Averaged Rewarded Policies                                                          | [Link](https://arxiv.org/abs/2406.16768) |
| 188          | Adam-mini: Use Fewer Learning Rates To Gain More                                                                    | [Link](https://arxiv.org/abs/2406.16793) |
| 189          | The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale                                           | [Link](https://arxiv.org/abs/2406.17557) |
| 190          | LongIns: A Challenging Long-context Instruction-based Exam for LLMs                                                 | [Link](https://arxiv.org/abs/2406.17588) |
| 191          | Following Length Constraints in Instructions                                                                        | [Link](https://arxiv.org/abs/2406.17744) |
| 192          | A Closer Look into Mixture-of-Experts in Large Language Models                                                     | [Link](https://arxiv.org/abs/2406.18219) |
| 193          | RouteLLM: Learning to Route LLMs with Preference Data                                                               | [Link](https://arxiv.org/abs/2406.18665) |
| 194          | Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of LLMs                                        | [Link](https://arxiv.org/abs/2406.18629) |
| 195          | Dataset Size Recovery from LoRA Weights                                                                            | [Link](https://arxiv.org/abs/2406.19395) |
| 196          | From Artificial Needles to Real Haystacks: Improving Retrieval Capabilities in LLMs by Finetuning on Synthetic Data | [Link](https://arxiv.org/abs/2406.19292) |
| 197          | Changing Answer Order Can Decrease MMLU Accuracy                                                                   | [Link](https://arxiv.org/abs/2406.19470) |
| 198          | Direct Preference Knowledge Distillation for Large Language Models                                                 | [Link](https://arxiv.org/abs/2406.19774) |
| 199          | LLM Critics Help Catch LLM Bugs                                                                                    | [Link](https://arxiv.org/abs/2407.00215) |
| 200          | Scaling Synthetic Data Creation with 1,000,000,000 Personas                                                        | [Link](https://arxiv.org/abs/2406.20094) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 201          | Tokenization Falling Short: The Curse of Tokenization                                                              | [Link](https://arxiv.org/abs/2406.11687) |
| 202          | Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs                                    | [Link](https://arxiv.org/abs/2406.10216) |
| 203          | Bootstrapping Language Models with DPO Implicit Rewards                                                           | [Link](https://arxiv.org/abs/2406.09760) |
| 204          | Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges                                     | [Link](https://arxiv.org/abs/2406.12624) |
| 205          | Learning and Leveraging World Models in Visual Representation Learning                                                | [Link](https://arxiv.org/abs/2403.00504) |
| 206          | Improving LLM Code Generation with Grammar Augmentation                                                              | [Link](https://arxiv.org/abs/2403.01632) |
| 207          | The Hidden Attention of Mamba Models                                                                                 | [Link](https://arxiv.org/abs/2403.01590) |
| 208          | Training-Free Pretrained Model Merging                                                                               | [Link](https://arxiv.org/abs/2403.01753) |
| 209          | Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures                                   | [Link](https://arxiv.org/abs/2403.02308) |
| 210          | The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning                                             | [Link](https://arxiv.org/abs/2403.03218) |
| 211          | Evolution Transformer: In-Context Evolutionary Optimization                                                         | [Link](https://arxiv.org/abs/2403.02985) |
| 212          | Enhancing Vision-Language Pre-training with Rich Supervisions                                                       | [Link](https://arxiv.org/abs/2403.03346) |
| 213          | Scaling Rectified Flow Transformers for High-Resolution Image Synthesis                                             | [Link](https://arxiv.org/abs/2403.03206) |
| 214          | Design2Code: How Far Are We From Automating Front-End Engineering?                                                  | [Link](https://arxiv.org/abs/2403.03163) |
| 215          | ShortGPT: Layers in Large Language Models are More Redundant Than You Expect                                        | [Link](https://arxiv.org/abs/2403.03853) |
| 216          | Backtracing: Retrieving the Cause of the Query                                                                      | [Link](https://arxiv.org/abs/2403.03956) |
| 217          | Learning to Decode Collaboratively with Multiple Language Models                                                   | [Link](https://arxiv.org/abs/2403.03870) |
| 218          | SaulLM-7B: A pioneering Large Language Model for Law                                                               | [Link](https://arxiv.org/abs/2403.03883) |
| 219          | Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning        | [Link](https://arxiv.org/abs/2403.03864) |
| 220          | 3D Diffusion Policy                                                                                                 | [Link](https://arxiv.org/abs/2403.03954) |
| 221          | MedMamba: Vision Mamba for Medical Image Classification                                                            | [Link](https://arxiv.org/abs/2403.03849) |
| 222          | GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection                                              | [Link](https://arxiv.org/abs/2403.03507) |
| 223          | Stop Regressing: Training Value Functions via Classification for Scalable Deep RL                                  | [Link](https://arxiv.org/abs/2403.03950) |
| 224          | How Far Are We from Intelligent Visual Deductive Reasoning?                                                        | [Link](https://arxiv.org/abs/2403.04732) |
| 225          | Common 7B Language Models Already Possess Strong Math Capabilities                                                | [Link](https://arxiv.org/abs/2403.04706) |
| 226          | Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context                                | [Link](https://arxiv.org/abs/2403.05530) |
| 227          | Is Cosine-Similarity of Embeddings Really About Similarity?                                                       | [Link](https://arxiv.org/abs/2403.05440) |
| 228          | LLM4Decompile: Decompiling Binary Code with Large Language Models                                                 | [Link](https://arxiv.org/abs/2403.05286) |
| 229          | Algorithmic Progress in Language Models                                                                           | [Link](https://arxiv.org/abs/2403.05812) |
| 230          | Stealing Part of a Production Language Model                                                                      | [Link](https://arxiv.org/abs/2403.06634) |
| 231          | Chronos: Learning the Language of Time Series                                                                     | [Link](https://arxiv.org/abs/2403.07815) |
| 232          | Simple and Scalable Strategies to Continually Pre-train Large Language Models                                     | [Link](https://arxiv.org/abs/2403.08763) |
| 233          | Language Models Scale Reliably With Over-Training and on Downstream Tasks                                         | [Link](https://arxiv.org/abs/2403.08540) |
| 234          | BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences                         | [Link](https://arxiv.org/abs/2403.09347) |
| 235          | LocalMamba: Visual State Space Model with Windowed Selective Scan                                                | [Link](https://arxiv.org/abs/2403.09338) |
| 236          | GiT: Towards Generalist Vision Transformer through Universal Language Interface                                   | [Link](https://arxiv.org/abs/2403.09394) |
| 237          | MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training                                               | [Link](https://arxiv.org/abs/2403.09611) |
| 238          | RAFT: Adapting Language Model to Domain Specific RAG                                                             | [Link](https://arxiv.org/abs/2403.10131) |
| 239          | TnT-LLM: Text Mining at Scale with Large Language Models                                                         | [Link](https://arxiv.org/abs/2403.12173) |
| 240          | Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression                   | [Link](https://arxiv.org/abs/2403.15447) |
| 241          | PERL: Parameter Efficient Reinforcement Learning from Human Feedback                                             | [Link](https://arxiv.org/abs/2403.10704) |
| 242          | RewardBench: Evaluating Reward Models for Language Modeling                                                      | [Link](https://arxiv.org/abs/2403.13787) |
| 243          | LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models                                              | [Link](https://arxiv.org/abs/2403.13372) |
| 244          | RakutenAI-7B: Extending Large Language Models for Japanese                                                       | [Link](https://arxiv.org/abs/2403.15484) |
| 245          | SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time Series                               | [Link](https://arxiv.org/abs/2403.15360) |
| 246          | Can Large Language Models Explore In-Context?                                                                   | [Link](https://arxiv.org/abs/2403.15371) |
| 247          | LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement                                                    | [Link](https://arxiv.org/abs/2403.15042) |
| 248          | LLM Agent Operating System                                                                                      | [Link](https://arxiv.org/abs/2403.16971) |
| 249          | The Unreasonable Ineffectiveness of the Deeper Layers                                                           | [Link](https://arxiv.org/abs/2403.17887) |
| 250          | BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text                                            | [Link](https://arxiv.org/abs/2403.18421) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 251          | ViTAR: Vision Transformer with Any Resolution                                                                   | [Link](https://arxiv.org/abs/2403.18361) |
| 252          | Long-form Factuality in Large Language Models                                                                   | [Link](https://arxiv.org/abs/2403.18802) |
| 253          | Mini-Gemini: Mining the Potential of Multi-modality Vision Language Models                                      | [Link](https://arxiv.org/abs/2403.18814) |
| 254          | LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning                       | [Link](https://arxiv.org/abs/2403.17919) |
| 255          | Mechanistic Design and Scaling of Hybrid Architectures                                                         | [Link](https://arxiv.org/abs/2403.17844) |
| 256          | MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions                                         | [Link](https://arxiv.org/abs/2403.19651) |
| 257          | Model Stock: All We Need Is Just a Few Fine-Tuned Models                                                        | [Link](https://arxiv.org/abs/2403.19522) |
| 258          | Do Language Models Plan Ahead for Future Tokens?                                                                      | [Link](https://arxiv.org/abs/2404.00859) |
| 259          | Bigger is not Always Better: Scaling Properties of Latent Diffusion Models                                           | [Link](https://arxiv.org/abs/2404.01367) |
| 260          | The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis                   | [Link](https://arxiv.org/abs/2404.01204) |
| 261          | Diffusion-RWKV: Scaling RWKV-Like Architectures for Diffusion Models                                                 | [Link](https://arxiv.org/abs/2404.04478) |
| 262          | Mixture-of-Depths: Dynamically Allocating Compute in Transformer-Based Language Models                               | [Link](https://arxiv.org/abs/2404.02258) |
| 263          | Long-context LLMs Struggle with Long In-context Learning                                                             | [Link](https://arxiv.org/abs/2404.02060) |
| 264          | Emergent Abilities in Reduced-Scale Generative Language Models                                                      | [Link](https://arxiv.org/abs/2404.02204) |
| 265          | Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks                                              | [Link](https://arxiv.org/abs/2404.02151) |
| 266          | On the Scalability of Diffusion-based Text-to-Image Generation                                                      | [Link](https://arxiv.org/abs/2404.02883) |
| 267          | BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models                                  | [Link](https://arxiv.org/abs/2404.02827) |
| 268          | Cross-Attention Makes Inference Cumbersome in Text-to-Image Diffusion Models                                        | [Link](https://arxiv.org/abs/2404.02747) |
| 269          | Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences                         | [Link](https://arxiv.org/abs/2404.02151) |
| 270          | Training LLMs over Neurally Compressed Text                                                                        | [Link](https://arxiv.org/abs/2404.03626) |
| 271          | CantTalkAboutThis: Aligning Language Models to Stay on Topic in Dialogues                                           | [Link](https://arxiv.org/abs/2404.03820) |
| 272          | ReFT: Representation Finetuning for Language Models                                                                | [Link](https://arxiv.org/abs/2404.03592) |
| 273          | Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data                                      | [Link](https://arxiv.org/abs/2404.03862) |
| 274          | Sigma: Siamese Mamba Network for Multi-Modal Semantic Segmentation                                                 | [Link](https://arxiv.org/abs/2404.04256) |
| 275          | AutoCodeRover: Autonomous Program Improvement                                                                      | [Link](https://arxiv.org/abs/2404.05427) |
| 276          | Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence                                             | [Link](https://arxiv.org/abs/2404.05892) |
| 277          | CodecLM: Aligning Language Models with Tailored Synthetic Data                                                     | [Link](https://arxiv.org/abs/2404.05875) |
| 278          | MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies                        | [Link](https://arxiv.org/abs/2404.06395) |
| 279          | Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models                         | [Link](https://arxiv.org/abs/2404.06209) |
| 280          | LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders                                                | [Link](https://arxiv.org/abs/2404.05961) |
| 281          | Adapting LLaMA Decoder to Vision Transformer                                                                       | [Link](https://arxiv.org/abs/2404.06773) |
| 282          | Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention                             | [Link](https://arxiv.org/abs/2404.07143) |
| 283          | LLoCO: Learning Long Contexts Offline                                                                             | [Link](https://arxiv.org/abs/2404.07979) |
| 284          | JetMoE: Reaching Llama2 Performance with 0.1M Dollars                                                              | [Link](https://arxiv.org/abs/2404.07413) |
| 285          | Best Practices and Lessons Learned on Synthetic Data for Language Models                                          | [Link](https://arxiv.org/abs/2404.07503) |
| 286          | Rho-1: Not All Tokens Are What You Need                                                                           | [Link](https://arxiv.org/abs/2404.07965) |
| 287          | Pre-training Small Base LMs with Fewer Tokens                                                                     | [Link](https://arxiv.org/abs/2404.08634) |
| 288          | Dataset Reset Policy Optimization for RLHF                                                                           | [Link](https://arxiv.org/abs/2404.08495) |
| 289          | LLM In-Context Recall is Prompt Dependent                                                                            | [Link](https://arxiv.org/abs/2404.08865) |
| 290          | State Space Model for New-Generation Network Alternative to Transformers: A Survey                                   | [Link](https://arxiv.org/abs/2404.09516) |
| 291          | Chinchilla Scaling: A Replication Attempt                                                                            | [Link](https://arxiv.org/abs/2404.10102) |
| 292          | Learn Your Reference Model for Real Good Alignment                                                                  | [Link](https://arxiv.org/abs/2404.09656) |
| 293          | Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study                                                     | [Link](https://arxiv.org/abs/2404.10719) |
| 294          | Scaling (Down) CLIP: A Comprehensive Analysis of Data, Architecture, and Training Strategies                        | [Link](https://arxiv.org/abs/2404.08197) |
| 295          | How Faithful Are RAG Models? Quantifying the Tug-of-War Between RAG and LLMs‚Äô Internal Prior                        | [Link](https://arxiv.org/abs/2404.10198) |
| 296          | A Survey on Retrieval-Augmented Text Generation for Large Language Models                                           | [Link](https://arxiv.org/abs/2404.10981) |
| 297          | When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes                            | [Link](https://arxiv.org/abs/2404.12365) |
| 298          | Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing                                         | [Link](https://arxiv.org/abs/2404.12253) |
| 299          | OpenBezoar: Small, Cost-Effective and Open Models Trained on Mixes of Instruction Data                               | [Link](https://arxiv.org/abs/2404.12195) |
| 300          | The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions                                      | [Link](https://arxiv.org/abs/2404.13208) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 301          | How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study                                                    | [Link](https://arxiv.org/abs/2404.14047) |
| 302          | Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone                                       | [Link](https://arxiv.org/abs/2404.14219) |
| 303          | OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework                       | [Link](https://arxiv.org/abs/2404.14619) |
| 304          | A Survey on Self-Evolution of Large Language Models                                                                 | [Link](https://arxiv.org/abs/2404.14662) |
| 305          | Multi-Head Mixture-of-Experts                                                                                       | [Link](https://arxiv.org/abs/2404.15045) |
| 306          | NExT: Teaching Large Language Models to Reason about Code Execution                                                | [Link](https://arxiv.org/abs/2404.14662) |
| 307          | Graph Machine Learning in the Era of Large Language Models (LLMs)                                                  | [Link](https://arxiv.org/abs/2404.14928) |
| 308          | Retrieval Head Mechanistically Explains Long-Context Factuality                                                    | [Link](https://arxiv.org/abs/2404.15574) |
| 309          | Layer Skip: Enabling Early Exit Inference and Self-Speculative Decoding                                            | [Link](https://arxiv.org/abs/2404.16710) |
| 310          | Make Your LLM Fully Utilize the Context                                                                            | [Link](https://arxiv.org/abs/2404.16811) |
| 311          | LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report                                                | [Link](https://arxiv.org/abs/2405.00732) |
| 312          | Better & Faster Large Language Models via Multi-token Prediction                                                  | [Link](https://arxiv.org/abs/2404.19737) |
| 313          | RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing                         | [Link](https://arxiv.org/abs/2404.19543) |
| 314          | A Primer on the Inner Workings of Transformer-based Language Models                                                | [Link](https://arxiv.org/abs/2405.00208) |
| 315          | When to Retrieve: Teaching LLMs to Utilize Information Retrieval Effectively                                       | [Link](https://arxiv.org/abs/2404.19705) |
| 316          | KAN: Kolmogorov‚ÄìArnold Networks                                                                                   | [Link](https://arxiv.org/abs/2404.19756) |
| 317          | LLM See, LLM Do: Guiding Data Generation to Target Non-Differentiable Objectives                                      | [Link](https://arxiv.org/abs/2407.01490) |
| 318          | Searching for Best Practices in Retrieval-Augmented Generation                                                      | [Link](https://arxiv.org/abs/2407.01219) |
| 319          | Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models       | [Link](https://arxiv.org/abs/2407.01906) |
| 320          | Diffusion Forcing: Next-token Prediction Meets Full-Sequence Diffusion                                               | [Link](https://arxiv.org/abs/2407.01392) |
| 321          | Eliminating Position Bias of Language Models: A Mechanistic Approach                                                | [Link](https://arxiv.org/abs/2407.01100) |
| 322          | JMInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention                         | [Link](https://arxiv.org/abs/2407.02490) |
| 323          | TokenPacker: Efficient Visual Projector for Multimodal LLM                                                          | [Link](https://arxiv.org/abs/2407.02392) |
| 324          | Reasoning in Large Language Models: A Geometric Perspective                                                         | [Link](https://arxiv.org/abs/2407.02678) |
| 325          | RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs                                       | [Link](https://arxiv.org/abs/2407.02485) |
| 326          | AgentInstruct: Toward Generative Teaching with Agentic Flows                                                        | [Link](https://arxiv.org/abs/2407.03502) |
| 327          | HEMM: Holistic Evaluation of Multimodal Foundation Models                                                           | [Link](https://arxiv.org/abs/2407.03418) |
| 328          | Mixture of A Million Experts                                                                                        | [Link](https://arxiv.org/abs/2407.04153) |
| 329          | Learning to (Learn at Test Time): RNNs with Expressive Hidden States                                                | [Link](https://arxiv.org/abs/2407.04620) |
| 330          | Vision Language Models Are Blind                                                                                    | [Link](https://arxiv.org/abs/2407.06581) |
| 331          | Self-Recognition in Language Models                                                                                 | [Link](https://arxiv.org/abs/2407.06946) |
| 332          | Inference Performance Optimization for Large Language Models on CPUs                                                | [Link](https://arxiv.org/abs/2407.07304) |
| 333          | Gradient Boosting Reinforcement Learning                                                                            | [Link](https://arxiv.org/abs/2407.08250) |
| 334          | FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision                                     | [Link](https://arxiv.org/abs/2407.08608) |
| 335          | SpreadsheetLLM: Encoding Spreadsheets for Large Language Models                                                     | [Link](https://arxiv.org/abs/2407.09025) |
| 336          | New Desiderata for Direct Preference Optimization                                                                   | [Link](https://arxiv.org/abs/2407.09072) |
| 337          | Context Embeddings for Efficient Answer Generation in RAG                                                          | [Link](https://arxiv.org/abs/2407.09252) |
| 338          | Qwen2 Technical Report                                                                                              | [Link](https://arxiv.org/abs/2407.10671) |
| 339          | The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism                             | [Link](https://arxiv.org/abs/2407.10457) |
| 340          | From GaLore to WeLore: How Low-Rank Weights Non-uniformly Emerge from Low-Rank Gradients                            | [Link](https://arxiv.org/abs/2407.11239) |
| 341          | GoldFinch: High Performance RWKV/Transformer Hybrid with Linear Pre-Fill and Extreme KV-Cache Compression           | [Link](https://arxiv.org/abs/2407.12077) |
| 342          | Scaling Diffusion Transformers to 16 Billion Parameters                                                            | [Link](https://arxiv.org/abs/2407.11633) |
| 343          | NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?                                       | [Link](https://arxiv.org/abs/2407.11963) |
| 344          | Patch-Level Training for Large Language Models                                                                     | [Link](https://arxiv.org/abs/2407.12665) |
| 345          | LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models                                              | [Link](https://arxiv.org/abs/2407.12772) |
| 346          | A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks                            | [Link](https://arxiv.org/abs/2407.12994) |
| 347          | Spectra: A Comprehensive Study of Ternary, Quantized, and FP16 Language Models                                      | [Link](https://arxiv.org/abs/2407.12327) |
| 348          | Attention Overflow: Language Model Input Blur during Long-Context Missing Items Recommendation                     | [Link](https://arxiv.org/abs/2407.13481) |
| 349          | Weak-to-Strong Reasoning                                                                                           | [Link](https://arxiv.org/abs/2407.13647) |
| 350          | Understanding Reference Policies in Direct Preference Optimization                                                 | [Link](https://arxiv.org/abs/2407.13709) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 351          | Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies                                            | [Link](https://arxiv.org/abs/2407.13623) |
| 352          | BOND: Aligning LLMs with Best-of-N Distillation                                                                    | [Link](https://arxiv.org/abs/2407.14622) |
| 353          | Compact Language Models via Pruning and Knowledge Distillation                                                    | [Link](https://arxiv.org/abs/2407.14679) |
| 354          | LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference                                           | [Link](https://arxiv.org/abs/2407.14057) |
| 355          | Mini-Sequence Transformer: Optimizing Intermediate Memory for Long Sequences Training                              | [Link](https://arxiv.org/abs/2407.15892) |
| 356          | DDK: Distilling Domain Knowledge for Efficient Large Language Models                                              | [Link](https://arxiv.org/abs/2407.16154) |
| 357          | Generation Constraint Scaling Can Mitigate Hallucination                                                          | [Link](https://arxiv.org/abs/2407.16908) |
| 358          | Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach                    | [Link](https://arxiv.org/abs/2407.16833) |
| 359          | Course-Correction: Safety Alignment Using Synthetic Preferences                                                   | [Link](https://arxiv.org/abs/2407.16637) |
| 360          | Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?                                  | [Link](https://arxiv.org/abs/2407.16607) |
| 361          | Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge                                 | [Link](https://arxiv.org/abs/2407.19594) |
| 362          | Improving Retrieval Augmented Language Model with Self-Reasoning                                                  | [Link](https://arxiv.org/abs/2407.19813) |
| 363          | Apple Intelligence Foundation Language Models                                                                     | [Link](https://arxiv.org/abs/2407.21075) |
| 364          | ThinK: Thinner Key Cache by Query-Driven Pruning                                                                  | [Link](https://arxiv.org/abs/2407.21018) |
| 365          | The Llama 3 Herd of Models                                                                                       | [Link](https://arxiv.org/abs/2407.21783) |
| 366          | Gemma 2: Improving Open Language Models at a Practical Size                                                      | [Link](https://arxiv.org/abs/2408.00118) |
| 367          | SAM 2: Segment Anything in Images and Videos                                                                         | [Link](https://arxiv.org/abs/2408.00714) |
| 368          | POA: Pre-training Once for Models of All Sizes                                                                      | [Link](https://arxiv.org/abs/2408.01031) |
| 369          | RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework                                              | [Link](https://arxiv.org/abs/2408.01262) |
| 370          | A Survey of Mamba                                                                                                   | [Link](https://arxiv.org/abs/2408.01129) |
| 371          | MiniCPM-V: A GPT-4V Level MLLM on Your Phone                                                                       | [Link](https://arxiv.org/abs/2408.01800) |
| 372          | RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented Generation                                      | [Link](https://arxiv.org/abs/2408.02545) |
| 373          | Self-Taught Evaluators                                                                                             | [Link](https://arxiv.org/abs/2408.02666) |
| 374          | BioMamba: A Pre-trained Biomedical Language Representation Model Leveraging Mamba                                  | [Link](https://arxiv.org/abs/2408.02600) |
| 375          | EXAONE 3.0 7.8B Instruction Tuned Language Model                                                                   | [Link](https://arxiv.org/abs/2408.03541) |
| 376          | 1.5-Pints Technical Report: Pretraining in Days, Not Months ‚Äì Your Language Model Thrives on Quality Data           | [Link](https://arxiv.org/abs/2408.03506) |
| 377          | Conversational Prompt Engineering                                                                                  | [Link](https://arxiv.org/abs/2408.04560) |
| 378          | Trans-Tokenization and Cross-lingual Vocabulary Transfers: Language Adaptation of LLMs for Low-Resource NLP         | [Link](https://arxiv.org/abs/2408.04303) |
| 379          | The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery                                          | [Link](https://arxiv.org/abs/2408.06292) |
| 380          | Hermes 3 Technical Report                                                                                         | [Link](https://arxiv.org/abs/2408.12570) |
| 381          | Customizing Language Models with Instance-wise LoRA for Sequential Recommendation                                  | [Link](https://arxiv.org/abs/2408.10159) |
| 382          | Enhancing Robustness in Large Language Models: Prompting for Mitigating the Impact of Irrelevant Information        | [Link](https://arxiv.org/abs/2408.10615) |
| 383          | To Code, or Not To Code? Exploring Impact of Code in Pre-training                                                 | [Link](https://arxiv.org/abs/2408.10914) |
| 384          | LLM Pruning and Distillation in Practice: The Minitron Approach                                                    | [Link](https://arxiv.org/abs/2408.11796) |
| 385          | Jamba-1.5: Hybrid Transformer-Mamba Models at Scale                                                               | [Link](https://arxiv.org/abs/2408.12570) |
| 386          | Controllable Text Generation for Large Language Models: A Survey                                                  | [Link](https://arxiv.org/abs/2408.12599) |
| 387          | Multi-Layer Transformers Gradient Can be Approximated in Almost Linear Time                                       | [Link](https://arxiv.org/abs/2408.13233) |
| 388          | A Practitioner‚Äôs Guide to Continual Multimodal Pretraining                                                        | [Link](https://arxiv.org/abs/2408.14471) |
| 389          | Building and Better Understanding Vision-Language Models: Insights and Future Directions                          | [Link](https://arxiv.org/abs/2408.12637) |
| 390          | CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting Mitigation                                  | [Link](https://arxiv.org/abs/2408.14572) |
| 391          | The Mamba in the Llama: Distilling and Accelerating Hybrid Models                                                 | [Link](https://arxiv.org/abs/2408.15237) |
| 392          | ReMamba: Equip Mamba with Effective Long-Sequence Modeling                                                        | [Link](https://arxiv.org/abs/2408.15496) |
| 393          | Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling                                  | [Link](https://arxiv.org/abs/2408.16737) |
| 394          | LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models                             | [Link](https://arxiv.org/abs/2409.00509) |
| 395          | Switti: Designing Scale-Wise Transformers for Text-to-Image Synthesis                                                | [Link](https://arxiv.org/abs/2412.01819) |
| 396          | X-Prompt: Towards Universal In-Context Image Generation in Auto-Regressive Vision Language Foundation Models          | [Link](https://arxiv.org/abs/2412.01824) |
| 397          | Free Process Rewards without Process Labels                                                                          | [Link](https://arxiv.org/abs/2412.01981) |
| 398          | Scaling Image Tokenizers with Grouped Spherical Quantization                                                        | [Link](https://arxiv.org/abs/2412.02632) |
| 399          | RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models                                           | [Link](https://arxiv.org/abs/2412.02830) |
| 400          | Perception Tokens Enhance Visual Reasoning in Multimodal Language Models                                            | [Link](https://arxiv.org/abs/2412.03548) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 401          | Evaluating Language Models as Synthetic Data Generators                                                             | [Link](https://arxiv.org/abs/2412.03679) |
| 402          | Best-of-N Jailbreaking                                                                                              | [Link](https://arxiv.org/abs/2412.03556) |
| 403          | PaliGemma 2: A Family of Versatile VLMs for Transfer                                                                | [Link](https://arxiv.org/abs/2412.03555) |
| 404          | VisionZip: Longer is Better but Not Necessary in Vision Language Models                                             | [Link](https://arxiv.org/abs/2412.04467) |
| 405          | Evaluating and Aligning CodeLLMs on Human Preference                                                                | [Link](https://arxiv.org/abs/2412.05210) |
| 406          | MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale                                         | [Link](https://arxiv.org/abs/2412.05237) |
| 407          | Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling           | [Link](https://arxiv.org/abs/2412.05271) |
| 408          | LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods                                              | [Link](https://arxiv.org/abs/2412.05579) |
| 409          | Does RLHF Scale? Exploring the Impacts From Data, Model, and Method                                                | [Link](https://arxiv.org/abs/2412.06000) |
| 410          | Unraveling the Complexity of Memory in RL Agents: An Approach for Classification and Evaluation                     | [Link](https://arxiv.org/abs/2412.06531) |
| 411          | Training Large Language Models to Reason in a Continuous Latent Space                                              | [Link](https://arxiv.org/abs/2412.06769) |
| 412          | AutoReason: Automatic Few-Shot Reasoning Decomposition                                                             | [Link](https://arxiv.org/abs/2412.06975) |
| 413          | Large Concept Models: Language Modeling in a Sentence Representation Space                                         | [Link](https://arxiv.org/abs/2412.08821) |
| 414          | Phi-4 Technical Report                                                                                            | [Link](https://arxiv.org/abs/2412.08905) |
| 415          | Byte Latent Transformer: Patches Scale Better Than Tokens                                                          | [Link](https://arxiv.org/abs/2412.09871) |
| 416          | SCBench: A KV Cache-Centric Analysis of Long-Context Methods                                                      | [Link](https://arxiv.org/abs/2412.10319) |
| 417          | Cultural Evolution of Cooperation among LLM Agents                                                                | [Link](https://arxiv.org/abs/2412.10270) |
| 418          | DeepSeek-VL2: Mixture-of-Experts Vision-Language Models for Advanced Multimodal Understanding                      | [Link](https://arxiv.org/abs/2412.10302) |
| 419          | No More Adam: Learning Rate Scaling at Initialization is All You Need                                              | [Link](https://arxiv.org/abs/2412.11768) |
| 420          | Precise Length Control in Large Language Models                                                                   | [Link](https://arxiv.org/abs/2412.11937) |
| 421          | The Open Source Advantage in Large Language Models (LLMs)                                                         | [Link](https://arxiv.org/abs/2412.12004) |
| 422          | A Survey of Mathematical Reasoning in the Era of Multimodal Large Language Model: Benchmark, Method & Challenges   | [Link](https://arxiv.org/abs/2412.11936) |
| 423          | Are Your LLMs Capable of Stable Reasoning?                                                                        | [Link](https://arxiv.org/abs/2412.13147) |
| 424          | LLM Post-Training Recipes: Improving Reasoning in LLMs                                                            | [Link](https://arxiv.org/abs/2412.14135) |
| 425          | Hansel: Output Length Controlling Framework for Large Language Models                                             | [Link](https://arxiv.org/abs/2412.14033) |
| 426          | Mind Your Theory: Theory of Mind Goes Deeper Than Reasoning                                                       | [Link](https://arxiv.org/abs/2412.1363) |
| 427          | Alignment Faking in Large Language Models                                                                         | [Link](https://arxiv.org/abs/2412.14093) |
| 428          | SCOPE: Optimizing Key-Value Cache Compression in Long-Context Generation                                          | [Link](https://arxiv.org/abs/2412.13649) |
| 429          | LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-Context Multitasks                     | [Link](https://arxiv.org/abs/2412.15204) |
| 430          | Offline Reinforcement Learning for LLM Multi-Step Reasoning                                                      | [Link](https://arxiv.org/abs/2412.16145) |
| 431          | Mulberry: Empowering MLLM with O1-like Reasoning and Reflection via Collective Monte Carlo Tree Search            | [Link](https://arxiv.org/abs/2412.18319) |
| 432          | Titans: Learning to Memorize at Test Time                                                                         | [Link](https://arxiv.org/abs/2501.00663) |
| 433          | Addition is All You Need for Energy-efficient Language Models                                                        | [Link](https://arxiv.org/abs/2410.00907) |
| 434          | Quantifying Generalization Complexity for Large Language Models                                                     | [Link](https://arxiv.org/abs/2410.01769) |
| 435          | When a Language Model is Optimized for Reasoning, Does It Still Show Embers of Autoregression?                       | [Link](https://arxiv.org/abs/2410.01792) |
| 436          | Were RNNs All We Needed?                                                                                            | [Link](https://arxiv.org/abs/2410.01201) |
| 437          | Selective Attention Improves Transformer                                                                            | [Link](https://arxiv.org/abs/2410.02703) |
| 438          | LLMs Know More Than They Show: On the Intrinsic Representation of LLM Hallucinations                                | [Link](https://arxiv.org/abs/2410.02707) |
| 439          | LLaVA-Critic: Learning to Evaluate Multimodal Models                                                                | [Link](https://arxiv.org/abs/2410.02712) |
| 440          | Differential Transformer                                                                                           | [Link](https://arxiv.org/abs/2410.05258) |
| 441          | GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models                     | [Link](https://arxiv.org/abs/2410.05229) |
| 442          | ARIA: An Open Multimodal Native Mixture-of-Experts Model                                                           | [Link](https://arxiv.org/abs/2410.05993) |
| 443          | O1 Replication Journey: A Strategic Progress Report ‚Äì Part 1                                                      | [Link](https://arxiv.org/abs/2410.18982) |
| 444          | Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG                                           | [Link](https://arxiv.org/abs/2410.05983) |
| 445          | From Generalist to Specialist: Adapting Vision Language Models via Task-Specific Visual Instruction Tuning          | [Link](https://arxiv.org/abs/2410.06456) |
| 446          | KV Prediction for Improved Time to First Token                                                                     | [Link](https://arxiv.org/abs/2410.08391) |
| 447          | Baichuan-Omni Technical Report                                                                                    | [Link](https://arxiv.org/abs/2410.08565) |
| 448          | MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models                      | [Link](https://arxiv.org/abs/2410.10139) |
| 449          | LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models                             | [Link](https://arxiv.org/abs/2410.09732) |
| 450          | AFlow: Automating Agentic Workflow Generation                                                                      | [Link](https://arxiv.org/abs/2410.10762) |
|--------------|--------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 451          | Toward General Instruction-Following Alignment for Retrieval-Augmented Generation                                  | [Link](https://arxiv.org/abs/2410.09584) |
| 452          | Pre-training Distillation for Large Language Models: A Design Space Exploration                                    | [Link](https://arxiv.org/abs/2410.16215) |
| 453          | MIA-DPO: Multi-Image Augmented Direct Preference Optimization For Large Vision-Language Models                     | [Link](https://arxiv.org/abs/2410.17637) |
| 454          | Scalable Ranked Preference Optimization for Text-to-Image Generation                                               | [Link](https://arxiv.org/abs/2410.18013) |
| 455          | Scaling Diffusion Language Models via Adaptation from Autoregressive Models                                        | [Link](https://arxiv.org/abs/2410.17891) |
| 456          | Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback                                          | [Link](https://arxiv.org/abs/2410.19133) |
| 457          | Counting Ability of Large Language Models and Impact of Tokenization                                               | [Link](https://arxiv.org/abs/2410.19730) |
| 458          | A Survey of Small Language Models                                                                                 | [Link](https://arxiv.org/abs/2410.20011) |
| 459          | Accelerating Direct Preference Optimization with Prefix Sharing                                                   | [Link](https://arxiv.org/abs/2410.20305) |
| 460          | Mind Your Step (by Step): Chain-of-Thought Can Reduce Performance on Tasks Where Thinking Makes Humans Worse       | [Link](https://arxiv.org/abs/2410.21333) |
| 461          | LongReward: Improving Long-context Large Language Models with AI Feedback                                         | [Link](https://arxiv.org/abs/2410.21252) |
| 462          | ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference                                      | [Link](https://arxiv.org/abs/2410.21465) |
| 463          | Beyond Text: Optimizing RAG with Multimodal Inputs for Industrial Applications                                     | [Link](https://arxiv.org/abs/2410.21943) |
| 464          | CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation                                   | [Link](https://arxiv.org/abs/2410.23090) |
| 465          | What Happened in LLMs Layers When Trained for Fast vs. Slow Thinking: A Gradient Perspective                      | [Link](https://arxiv.org/abs/2410.23743) |
| 466          | GPT or BERT: Why Not Both?                                                                                        | [Link](https://arxiv.org/abs/2410.24159) |
| 467          | Language Models Can Self-Lengthen to Generate Long Texts                                                         | [Link](https://arxiv.org/abs/2410.23933) |
| 468          | OLMoE: Open Mixture-of-Experts Language Models                                                                       | [Link](https://arxiv.org/abs/2409.02060) |
| 469          | In Defense of RAG in the Era of Long-Context Language Models                                                        | [Link](https://arxiv.org/abs/2409.01666) |
| 470          | Attention Heads of Large Language Models: A Survey                                                                  | [Link](https://arxiv.org/abs/2409.03752) |
| 471          | LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA                                       | [Link](https://arxiv.org/abs/2409.02897) |
| 472          | How Do Your Code LLMs Perform? Empowering Code Instruction Tuning with High-Quality Data                            | [Link](https://arxiv.org/abs/2409.03810) |
| 473          | Theory, Analysis, and Best Practices for Sigmoid Self-Attention                                                    | [Link](https://arxiv.org/abs/2409.04431) |
| 474          | LLaMA-Omni: Seamless Speech Interaction with Large Language Models                                                 | [Link](https://arxiv.org/abs/2409.06666) |
| 475          | What is the Role of Small Models in the LLM Era: A Survey                                                          | [Link](https://arxiv.org/abs/2409.06857) |
| 476          | Policy Filtration in RLHF to Fine-Tune LLM for Code Generation                                                     | [Link](https://arxiv.org/abs/2409.06957) |
| 477          | RetrievalAttention: Accelerating Long-Context LLM Inference via Vector Retrieval                                   | [Link](https://arxiv.org/abs/2409.10516) |
| 478          | Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement                               | [Link](https://arxiv.org/abs/2409.12122) |
| 479          | Qwen2.5-Coder Technical Report                                                                                     | [Link](https://arxiv.org/abs/2409.12186) |
| 480          | Instruction Following without Instruction Tuning                                                                   | [Link](https://arxiv.org/abs/2409.14254) |
| 481          | Is Preference Alignment Always the Best Option to Enhance LLM-Based Translation? An Empirical Analysis            | [Link](https://arxiv.org/abs/2409.20059) |
| 482          | The Perfect Blend: Redefining RLHF with Mixture of Judges                                                          | [Link](https://arxiv.org/abs/2409.20370) |
| 483          | Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations                                     | [Link](https://arxiv.org/abs/2411.00640) |
| 484          | Adapting While Learning: Grounding LLMs for Scientific Problems with Intelligent Tool Usage Adaptation              | [Link](https://arxiv.org/abs/2411.00412) |
| 485          | Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models                        | [Link](https://arxiv.org/abs/2411.00492) |
| 486          | Sample-Efficient Alignment for LLMs                                                                                 | [Link](https://arxiv.org/abs/2411.01493) |
| 487          | A Comprehensive Survey of Small Language Models in the Era of Large Language Models                                 | [Link](https://arxiv.org/abs/2411.03350) |
| 488          | ‚ÄúGive Me BF16 or Give Me Death‚Äù? Accuracy-Performance Trade-Offs in LLM Quantization                                | [Link](https://arxiv.org/abs/2411.02355) |
| 489          | Parameter-Efficient Fine-Tuning of Large Language Models for Unit Test Generation                                   | [Link](https://arxiv.org/abs/2411.02462) |
| 490          | HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge in RAG Systems                             | [Link](https://arxiv.org/abs/2411.02959) |
| 491          | Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM Data Contamination                             | [Link](https://arxiv.org/abs/2411.03823) |
| 492          | Language Models are Hidden Reasoners: Unlocking Latent Reasoning Capabilities via Self-Rewarding                   | [Link](https://arxiv.org/abs/2411.04282) |
| 493          | Number Cookbook: Number Understanding of Language Models and How to Improve It                                     | [Link](https://arxiv.org/abs/2411.03766) |
| 494          | Mixture-of-Transformers: A Sparse and Scalable Architecture for Multi-Modal Foundation Models                      | [Link](https://arxiv.org/abs/2411.04996) |
| 495          | BitNet a4.8: 4-bit Activations for 1-bit LLMs                                                                       | [Link](https://arxiv.org/abs/2411.04965) |
| 496          | Scaling Laws for Precision                                                                                        | [Link](https://arxiv.org/abs/2411.04330) |
| 497          | Energy Efficient Protein Language Models                                                                           | [Link](https://arxiv.org/abs/2411.05966) |
| 498          | Balancing Pipeline Parallelism with Vocabulary Parallelism                                                        | [Link](https://arxiv.org/abs/2411.05288) |
| 499          | Toward Optimal Search and Retrieval for RAG                                                                        | [Link](https://arxiv.org/abs/2411.07396) |
| 500          | Large Language Models Can Self-Improve in Long-context Reasoning                                                  | [Link](https://arxiv.org/abs/2411.08147) |
|--------------|-----------------------------------------------------------------------------------------------------------------------|-------------------------------------|
| 501          | Stronger Models are NOT Stronger Teachers for Instruction Tuning                                                  | [Link](https://arxiv.org/abs/2411.07133) |
| 502          | Direct Preference Optimization Using Sparse Feature-Level Constraints                                             | [Link](https://arxiv.org/abs/2411.07618) |
| 503          | Cut Your Losses in Large-Vocabulary Language Models                                                               | [Link](https://arxiv.org/abs/2411.09009) |
| 504          | Does Prompt Formatting Have Any Impact on LLM Performance?                                                        | [Link](https://arxiv.org/abs/2411.10541) |
| 505          | SymDPO: Boosting In-Context Learning of Large Multimodal Models                                                   | [Link](https://arxiv.org/abs/2411.11909) |
| 506          | SageAttention2 Technical Report                                                                                   | [Link](https://arxiv.org/abs/2411.10958) |
| 507          | Bi-Mamba: Towards Accurate 1-Bit State Space Models                                                               | [Link](https://arxiv.org/abs/2411.11843) |
| 508          | RedPajama: An Open Dataset for Training Large Language Models                                                     | [Link](https://arxiv.org/abs/2411.12372) |
| 509          | Hymba: A Hybrid-head Architecture for Small Language Models                                                      | [Link](https://arxiv.org/abs/2411.13676) |
| 510          | Loss-to-Loss Prediction: Scaling Laws for All Datasets                                                            | [Link](https://arxiv.org/abs/2411.12925) |
| 511          | When Precision Meets Position: BFloat16 Breaks Down RoPE in Long-Context Training                                 | [Link](https://arxiv.org/abs/2411.13476) |
| 512          | Multimodal Autoregressive Pre-training of Large Vision Encoders                                                  | [Link](https://arxiv.org/abs/2411.14402) |
| 513          | Natural Language Reinforcement Learning                                                                          | [Link](https://arxiv.org/abs/2411.14251) |
| 514          | Large Multi-modal Models Can Interpret Features in Large Multi-modal Models                                       | [Link](https://arxiv.org/abs/2411.14982) |
| 515          | T√úLU 3: Pushing Frontiers in Open Language Model Post-Training                                                   | [Link](https://arxiv.org/abs/2411.15124) |
| 516          | MME-Survey: A Comprehensive Survey on Evaluation of Multimodal LLMs                                              | [Link](https://arxiv.org/abs/2411.15296) |
| 517          | LLMs Do Not Think Step-by-step In Implicit Reasoning                                                             | [Link](https://arxiv.org/abs/2411.15862) |
| 518          | O1 Replication Journey ‚Äì Part 2                                                                                  | [Link](https://arxiv.org/abs/2411.16489) |
| 519          | Star Attention: Efficient LLM Inference over Long Sequences                                                      | [Link](https://arxiv.org/abs/2411.17116) |
| 520          | Low-Bit Quantization Favors Undertrained LLMs                                                                    | [Link](https://arxiv.org/abs/2411.17691) |
| 521          | Rethinking Token Reduction in MLLMs                                                                              | [Link](https://arxiv.org/abs/2411.17686) |
| 522          | Reverse Thinking Makes LLMs Stronger Reasoners                                                                   | [Link](https://arxiv.org/abs/2411.19865) |
| 523          | Critical Tokens Matter                                                                                          | [Link](https://arxiv.org/abs/2411.19943) |

---

üìå *Explore cutting-edge research ‚ú® and stay updated!* üß†üåü
